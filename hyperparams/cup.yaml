units: [[10, 64, 32, 16, 3]]
activations: [['relu', 'relu', 'relu', 'identity']]
weight_initializer: ['glorot_uniform']
bias_initializer: ['zeros']
learning_rate: [0.0006, 0.0005, 0.0007]
momentum: [0.73, 0.75, 0.77]
loss: ['mean_squared_error']
metrics: [['root_mean_squared_error']]
epochs: [4000]
batch_size: [8, 12]
