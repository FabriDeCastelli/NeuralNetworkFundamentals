units: [[10, 64, 32, 16, 3]]
activations: [['relu', 'relu', 'relu', 'identity']]
weight_initializer: ['glorot_uniform']
bias_initializer: ['zeros']
learning_rate: [0.000575, 0.0006, 0.000625]
momentum: [0.74, 0.75, 0.76, 0.77]
loss: ['mean_squared_error']
metrics: [['root_mean_squared_error', 'mean_euclidean_error']]
epochs: [15000]
batch_size: [12, 8]
start_from_epoch: [7000]
patience: [70, 90]
delta: [0.001]
monitor: ['mean_squared_error']
restore_best_weights: [True]
