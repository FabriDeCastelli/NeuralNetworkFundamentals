units: [[10, 64, 32, 16, 3]]
activations: [['relu', 'relu', 'relu', 'identity']]
weight_initializer: ['glorot_uniform']
bias_initializer: ['zeros']
learning_rate: [0.00055, 0.0005, 0.0006]
momentum: [0.77, 0.75, 0.76]
loss: ['mean_squared_error']
metrics: [['root_mean_squared_error', 'mean_euclidean_error']]
epochs: [100]
batch_size: [12, 8]
start_from_epoch: [3500]
patience: [50, 70]
delta: [0.001, 0.005]
monitor: ['mean_squared_error']
restore_best_weights: [False, True]
