units: [[10, 64, 32, 16, 3]]
activations: [['relu', 'relu', 'relu', 'identity']]
weight_initializer: ['glorot_uniform']
bias_initializer: ['zeros']
learning_rate: [0.00055, 0.0005, 0.00045]
momentum: [0.73, 0.75, 0.77]
loss: ['mean_squared_error']
metrics: [['root_mean_squared_error', 'mean_euclidean_error']]
epochs: [12000]
batch_size: [12]
